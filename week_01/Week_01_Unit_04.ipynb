{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enterprise Deep Learning with TensorFlow: openSAP \n",
    "\n",
    "## SAP Innovation Center Network\n",
    "```\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implemention of Single-layer Neural Network using NumPy\n",
    "\n",
    "The human brain is remarkable at learning new tasks and this is made possible by the neurons. \n",
    "Neurons learn through the process of trial and error, which we will be mimicking in this notebook.\n",
    "#### Task\n",
    "We will build a neural network that learns to predict 1 when a certain neuron is 1.\n",
    "\n",
    "**Train data**\n",
    "\n",
    "Input_1 | Input_2 | Input_3 | Output |\n",
    ":-------------: |:-------------: | :-------------: | :-------------: |\n",
    "0 | 0 | 0 | 0 \n",
    "0 | 0 | 1 | 0 \n",
    "0 | 1 | 0 | 1 \n",
    "1 | 0 | 0 | 0 \n",
    "1 | 1 | 0 | 1 \n",
    "1 | 1 | 1 | 1 \n",
    "\n",
    "#### Network Structure\n",
    "Our network has three inputs, three weights and one output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import exp, array, random, dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SingleNeuronNetwork():\n",
    "    def __init__(self):\n",
    "        # Set the seed for the random number generator\n",
    "        # Ensures same random numbers are produced every time the program is run\n",
    "        random.seed(42)\n",
    "\n",
    "        # --- Model a single neuron: 3 input connections and 1 output connection ---\n",
    "        # Assign random weights to a 3 x 1 matrix: Floating-point values in (-1, 1)\n",
    "        self.weights = 2 * random.random((3, 1)) - 1\n",
    "\n",
    "    # --- Define the Sigmoid function ---\n",
    "    # Pass the weighted sum of inputs through this function to normalize between [0, 1]\n",
    "    def __sigmoid(self, x):\n",
    "        return 1 / (1 + exp(-x))\n",
    "\n",
    "    # --- Define derivative of the Sigmoid function ---\n",
    "    # Evaluates confidence of existing learnt weights\n",
    "    def __sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    # --- Define the training procedure ---\n",
    "    # Modufy weights by calculating error after every iteration\n",
    "    def train(self, train_inputs, train_outputs, num_iterations):\n",
    "        # We run the training for num_iteration times\n",
    "        for iteration in range(num_iterations):\n",
    "            # Feed-forward the training set through the single neuron neural network\n",
    "            output = self.feed_forward(train_inputs)\n",
    "\n",
    "            # Calculate the error in predicted output \n",
    "            # Difference between the desired output and the feed-forward output\n",
    "            error = train_outputs - output\n",
    "\n",
    "            # Multiply the error by the input and again by the gradient of Sigmoid curve\n",
    "            # 1. Less confident weights are adjusted more\n",
    "            # 2. Inputs, that are zero, do not cause changes to the weights\n",
    "            adjustment = dot(train_inputs.T, error * \n",
    "                             self.__sigmoid_derivative(output))\n",
    "\n",
    "            # Make adjustments to the weights\n",
    "            self.weights += adjustment\n",
    "\n",
    "    # --- Define feed-forward procedure ---\n",
    "    def feed_forward(self, inputs):\n",
    "        # Feed-forward inputs through the single-neuron neural network\n",
    "        return self.__sigmoid(dot(inputs, self.weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Intialise a single-neuron neural network.\n",
    "neural_network = SingleNeuronNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network weights before training (random initialization): \n",
      "[[-0.25091976]\n",
      " [ 0.90142861]\n",
      " [ 0.46398788]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Neural network weights before training (random initialization): \")\n",
    "print (neural_network.weights)\n",
    "\n",
    "# The train data consists of 6 examples, each consisting of 3 inputs and 1 output\n",
    "train_inputs = array([[0, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 1], [1, 0, 0], [1, 1, 0]])\n",
    "train_outputs = array([[0, 1, 0, 1, 0, 1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network weights after training: \n",
      "[[ -4.21652261]\n",
      " [ 12.79677774]\n",
      " [ -4.21664048]]\n"
     ]
    }
   ],
   "source": [
    "# Train the neural network using a train inputs.\n",
    "# Train the network for 10,000 steps while modifying weights to reduce error.\n",
    "neural_network.train(train_inputs, train_outputs, 10000)\n",
    "\n",
    "print (\"Neural network weights after training: \")\n",
    "print (neural_network.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test data**\n",
    "\n",
    "Now that we have trained the network, let us use the weights of the trained network to predict inputs that were not used to train the network:\n",
    "\n",
    "Input_1 | Input_2 | Input_3 | Expected Output |\n",
    ":-------------: |:-------------: | :-------------: | :-------------: |\n",
    "1 | 0 | 0 | 0 \n",
    "0 | 1 | 1 | 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferring predicting from the network for [1, 0, 0] -> ?: \n",
      "[ 0.01453545]\n"
     ]
    }
   ],
   "source": [
    "# Test the neural network with a new input\n",
    "print (\"Inferring predicting from the network for [1, 0, 0] -> ?: \")\n",
    "print (neural_network.feed_forward(array([1, 0, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferring predicting from the network for [0, 1, 1] -> ?: \n",
      "[ 0.99981224]\n"
     ]
    }
   ],
   "source": [
    "print (\"Inferring predicting from the network for [0, 1, 1] -> ?: \")\n",
    "print (neural_network.feed_forward(array([0, 1, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
